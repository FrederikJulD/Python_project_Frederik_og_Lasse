{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personal-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'C:\\\\code\\\\python_for_the_financial_economist\\\\')\n",
    "\n",
    "\"\"\"\n",
    "Magic commands\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# animations, etc. requires below magic command\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load relevant packages\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib import animation, cm\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#import autograd\n",
    "# functions to approx derivative and hessian \n",
    "from statsmodels.tools.numdiff import approx_fprime, approx_hess\n",
    "\n",
    "\"\"\"\n",
    "Own packages\n",
    "\"\"\"\n",
    "\n",
    "from codelib.visualization.layout import DefaultStyle\n",
    "DefaultStyle();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-accident",
   "metadata": {},
   "source": [
    "# Introduction to estimation \n",
    "\n",
    "Estimation is key in financial economics!  The distribution of market invariants (e.g. returns) will generally be unknown and even if we can assume a particular distribution we need to be able to estimate the parameters describing the particular distribution. \n",
    "\n",
    "The choice of estimator will depend on a range of factors. Generally, the [variance-bias tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) tells us that we with large amounts of data can apply very flexible non-parametric estimators while we may need to impose distributional assumptions or even shrinkage with less data. \n",
    "\n",
    "## What is an estimator? \n",
    "\n",
    "An [estimator](https://en.wikipedia.org/wiki/Estimator), typically denoted $\\hat{\\theta} (\\mathbf{X})$, maps a random sample $X_1, ..., X_n$ (stacked in the vector $\\mathbf{X}$) defined by e.g. the pdf $f_X(x;\\theta)$, where $\\theta$ is an unknown parameter, to a set of _sample estimates_. It is important to note that the estimator is a function of random variables and therefore itself a random variable. \n",
    "\n",
    "For a particular realization of the random sample $x_1, ..., x_n$ (stacked in the vector $\\mathbf{x}$), we obtain the estimate $\\hat{\\theta} (\\mathbf{x})$ which is a fixed value. \n",
    "\n",
    "Some well-known estimators include the _sample mean_\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The _sample variance_\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The _sample covariance_\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "C_{X,Y} = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Properties of estimators \n",
    "\n",
    "We will discuss some important properties of estimators\n",
    "\n",
    "* Unbiasedness\n",
    "* Consistency\n",
    "* Efficiency\n",
    "* Asymptotic normality\n",
    "\n",
    "### Unbiasedness\n",
    "\n",
    "Estimators will take on different values from sample to sample (the estimate), but we would like the property that we on average get the right estimate. \n",
    "\n",
    "An estimator is said to be [unbiased](https://en.wikipedia.org/wiki/Bias_of_an_estimator) if its expected value is equal to the true value $\\theta$: \n",
    "\n",
    "$$\n",
    "\\text{E}[\\hat{\\theta} (\\mathbf{X})]  = \\theta\n",
    "$$\n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "Let $X_1,...,X_n$ be an independent sample of size $n$ all with the same pdf and mean $\\text{E}[X_i] = \\mu$. Define the sample mean\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "\\end{equation*} \n",
    "$$\n",
    "\n",
    "Then due to independence, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[\\bar{X}_n] &=  \\frac{1}{n} \\sum_{i=1}^n \\text{E}[X_i] = \\mu  \\\\\n",
    "\\text{Var}[\\bar{X}_n] &= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, the sample mean is an unbiased estimator. \n",
    "\n",
    "__Example: A single realization__\n",
    "\n",
    "Choosing the value of a single realization will also be an unbiased estimator since $\\text{E}[X_i] = \\mu$. The problem is of course that the variance of this estimator is $\\text{Var}[X_i] = \\sigma^2 > \\frac{\\sigma^2}{n}$. \n",
    "\n",
    "__Example: Sample variance__\n",
    "\n",
    "An natural estimator for the variance is given by\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "However, one can show that \n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{E}[\\hat{\\sigma}^2] = \\frac{n-1}{n} \\sigma^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Hence, it is not an unbiased estimator and we therefore typically use \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "### Consistency\n",
    "\n",
    "An estimator $\\hat{\\theta}(\\mathbf{X})$ is said to be [consistent](https://en.wikipedia.org/wiki/Consistent_estimator) for $\\theta$ if it converges in probability to $\\theta$ - that is, if for all $\\varepsilon>0$, \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to\\infty} P(\\vert \\hat{\\theta}(\\mathbf{X}) - \\theta\\vert < \\varepsilon) = 1\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which we also will write as \n",
    "\n",
    "$$\n",
    "\\text{plim } \\hat{\\theta}(\\mathbf{X}) = \\theta\n",
    "$$\n",
    "\n",
    "For consistency, it is sufficient to show that (almost sure convergence)\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty} \\text{E}[\\hat{\\theta}(\\mathbf{X})] = \\theta\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty}\\text{Var}[\\hat{\\theta}(\\mathbf{X})] = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "__Example: The sample mean__\n",
    "\n",
    "Again, let $X_1,...,X_n$ be an independent sample of size $n$ all with the same pdf and mean $\\text{E}[X_i] = \\mu$. \n",
    "\n",
    "The [Law of Large Numbers (LLN)](https://en.wikipedia.org/wiki/Law_of_large_numbers)  tells us (under some regularity conditions) that \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{plim } \\bar{X}_n = \\mu\n",
    "\\end{equation*}\n",
    "$$\n",
    "or more precisely \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n \\to \\infty} P(\\vert \\bar{X}_n - \\mu \\vert > \\varepsilon) = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "for all $\\varepsilon>0$. We call this for convergence in probability. \n",
    "\n",
    "We note that \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{E}[\\bar{X}_n] &=  \\frac{1}{n} \\sum_{i=1}^n \\text{E}[X_i] = \\mu  \\\\\n",
    "\\text{Var}[\\bar{X}_n] &= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "implying that the sample mean is unbiased and the variance converges to zero with the sample size. Thus, we have almost sure convergence. \n",
    "\n",
    "As an example, we consider the uniform distribution $X \\sim U(-5,5)$. Draw 10, 100, 500 and 1000 observations from the uniform distribution 10,000 times, calculate the sample mean for each iteration and blot the histogram of the sample means.\n",
    "\n",
    "We see that the distribution collapses around the true value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "round-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Draw uniform numbers\n",
    "\"\"\"\n",
    "a = -5.0\n",
    "b = 5.0\n",
    "\n",
    "uniform_data = np.random.uniform(low=a, high=b, size=(1000, 10000))\n",
    "\n",
    "true_var = (b-a)**2/12\n",
    "true_mean = (a + b)/2\n",
    "\n",
    "fig, ax_ = plt.subplots(2,2, figsize=(12,8))\n",
    "\n",
    "ax_ = ax_.flatten()\n",
    "\n",
    "\n",
    "for i, N in enumerate([10, 100, 500, 1000]): \n",
    "\n",
    "    ax = ax_[i]\n",
    "    \n",
    "    # get section of generated data\n",
    "    data = uniform_data[:N, :]\n",
    "    \n",
    "    # calculate sample means\n",
    "    sample_means = np.mean(data, axis=0)\n",
    "    \n",
    "    # plot histogram \n",
    "    ax.hist(sample_means, color=\"gray\", bins=100, zorder=1, density=True)\n",
    "    \n",
    "    ax.set_title(\"Histogram of sample mean for N = \" + str(N))\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim([-3.5,3.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-future",
   "metadata": {},
   "source": [
    "### Efficiency \n",
    "\n",
    "If we have two unbiased estimators for a parameter $\\theta$, $\\hat{\\theta}_1$ and $\\hat{\\theta}_2$, then if \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\hat{\\theta}_1] < \\text{Var}[\\hat{\\theta}_2]\n",
    "\\end{equation*}\n",
    "$$\n",
    "we say that $\\hat{\\theta}_1$ is more efficient than $\\hat{\\theta}_2$.\n",
    "\n",
    "\n",
    "A classical example (already mentioned) is that an element in a sample $X_i$ is an unbiased estimator of the expected value, just as the sample mean\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{E}[X_i] = \\mu\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "However, this estimator has the variance $\\sigma^2$ while the variance of the sample mean is \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\bar{X}] = \\frac{1}{n^2}\\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Clearly more efficient!\n",
    "\n",
    "__Cramér-Rao's lower bound__\n",
    "\n",
    "It will generally hold that if we have a random sample $X_1,...,X_n$ from the pdf $f_X(x;\\theta)$, where $\\theta$ is an unknown parameter and the estimator $\\hat{\\theta}(\\mathbf{X})$, then \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\hat{\\theta}] \\geq \\left[n \\text{E} \\left[ \\left(\\frac{\\partial \\ln f_X(X; \\theta)}{\\partial \\theta} \\right)^2\\right] \\right]^{-1} = \\left[ -n \\text{E} \\left[ \\frac{\\partial^2 \\ln f_X(X; \\theta)}{\\partial \\theta^2}\\right]\\right]^{-1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which is known as [Cramér-Rao's lower bound](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound). We will later see that the maximum-likelihood estimator satisfies Cramér-Rao's lower bound ensuring that the maximum-likelihood estimator is the most efficient. \n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "Let $X_1,...,X_n$ be an independent sample of size $n$ all with $X_i \\sim N(\\mu, \\sigma^2)$. Then, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ln f_X(X; \\mu, \\sigma)}{\\partial \\mu} = \\frac{\\partial }{\\partial \\mu} \\left[- \\ln (\\sigma \\sqrt{2\\pi}) -\\frac{(X-\\mu)^2}{2 \\sigma^2} \\right] = -2 \\frac{X-\\mu}{2 \\sigma^2} = -\\frac{X-\\mu}{ \\sigma^2} \n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\text{E}\\left[ \\left(-\\frac{X-\\mu}{ \\sigma^2} \\right)^2 \\right] = \\text{E}\\left[ \\frac{1}{\\sigma^2} \\frac{(X-\\mu)^2}{ \\sigma^2} \\right] =  \\frac{1}{\\sigma^2}  \\frac{ \\text{E}\\left[(X-\\mu)^2 \\right]}{ \\sigma^2} = \\frac{1}{\\sigma^2}  \\frac{ \\sigma^2}{ \\sigma^2} = \\frac{1}{\\sigma^2} \n",
    "$$\n",
    "\n",
    "Thus, the lower-bound for the variance is \n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\mu}] \\geq \\left[n  \\frac{1}{\\sigma^2} \\right]^{-1} = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "showing that the sample mean is the most efficient estimator (unbiased) in the normal case. \n",
    "\n",
    "\n",
    "### Asymptotic normality \n",
    "\n",
    "A consistent estimator is said to be asymptotically normally distributed if the distribution of the estimator converges to a normal distribution, typically, at the rate $1 / \\sqrt{n}$ (the standard deviation shrinks at this rate). We will write \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta} - \\theta) \\to^d N(0, V)\n",
    "$$\n",
    "\n",
    "where $V/n$ is called the asymptotic variance. \n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "[The Central Limit Theorem (CLT)](https://en.wikipedia.org/wiki/Central_limit_theorem) tells us that for an iid random sample of size $n$ and if $\\sigma < \\infty$\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty} P\\left(\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} < z \\right) = \\Phi(z)\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\Phi(z)$ denotes the standard normal cdf. \n",
    "\n",
    "It follows directly that \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\bar{X}_n - \\mu) \\to^d N\\left(0, \\frac{\\sigma^2}{n}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-yeast",
   "metadata": {},
   "source": [
    "## A brief look at Ordinary Least Squares (OLS)\n",
    "\n",
    "We will write a linear regression model (using matrix notation) as \n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{y}$ is the $n \\times 1$ vector of dependent variables, $\\mathbf{X}$ is the $n \\times k$ matrix of regressors (independent variables) and $\\mathbf{e}$ is the $n \\times 1$ error vector. \n",
    "\n",
    "As the name implies, the OLS estimator minimizes the sum of squared residuals \n",
    "\n",
    "$$\n",
    "Q_n (\\boldsymbol{\\beta}) = \\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top \\boldsymbol{\\beta} )^2 = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\top (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) = \\mathbf{e}^\\top \\mathbf{e}\n",
    "$$\n",
    "\n",
    "Taking the derivative wrt. $\\boldsymbol{\\beta}$ and setting equal to zero yields the estimator \n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{OLS} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "\n",
    "### Properties of OLS\n",
    "\n",
    "__Note__: It is not expected that you know all the finer details in deriving the asymptotic properties of e.g. the OLS estimator, but only how to implement derived formulas in Python. \n",
    "\n",
    "__Consistency__\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\boldsymbol{\\beta}}_{OLS} &= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y} \\\\\n",
    "&= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top (\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}) \\\\\n",
    "&= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{X}\\boldsymbol{\\beta} + (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{e} \\\\\n",
    "&= \\boldsymbol{\\beta} + (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{e} \\\\\n",
    "&= \\boldsymbol{\\beta} + \\left(\\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Basically, for consistency we need (without going into details)\n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X} = \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{X} \\right]  =  \\mathbf{M_{xx}}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{M_{xx}}$ is a non-singular matrix (invertible), and \n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} =  \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{e} \\right] =\\mathbf{0}\n",
    "$$\n",
    "\n",
    "requiring the regressors and error term to be uncorrelated. \n",
    "\n",
    "__Asymptotic normality__\n",
    "\n",
    "Rewritting the above expression yields \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) = \\left(\\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1} \\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e} \n",
    "$$\n",
    "\n",
    "If we can apply a CLT to $\\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e}$ such that it converges to multivariate normal distribution with finite, non-singular covariance matrix, we will have asymptotic normality. \n",
    "\n",
    "Assuming that \n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e} \\to^d N(\\mathbf{0}, \\mathbf{M_{x\\Omega x}})\n",
    "$$\n",
    "\n",
    "with  (here $\\boldsymbol{\\Omega}=\\text{E}[\\mathbf{e} \\mathbf{e}^\\top \\vert \\mathbf{X}] = \\text{Diag}[\\sigma_i^2]$ is the covariance matrix of the errors)\n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} \\mathbf{e}^\\top\\mathbf{X} = \\text{plim} \\frac{1}{n}\\mathbf{X}^\\top  \\boldsymbol{\\Omega} \\mathbf{X}  = \\mathbf{M_{x\\Omega x}}\n",
    "$$\n",
    "\n",
    "then it will be possible to show that \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) \\to^d N\\left(\\mathbf{0}, \\mathbf{M_{xx}}^{-1} \\mathbf{M_{x\\Omega x}}\\mathbf{M_{xx}}^{-1}\\right)\n",
    "$$\n",
    "\n",
    "__Homoskedasticity vs. heteroskedasticity__\n",
    "\n",
    "If $\\boldsymbol{\\Omega}=\\text{E}[\\mathbf{e}^\\top \\mathbf{e} \\vert \\mathbf{X}] = \\text{Diag}[\\sigma^2] = \\sigma^2 \\mathbf{I}$ then the error term is said to be homoskedastic and \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) \\to^d N\\left(\\mathbf{0}, \\sigma^2 \\mathbf{M_{xx}}^{-1} \\mathbf{M_{xx}}\\mathbf{M_{xx}}^{-1}\\right) = N\\left(\\mathbf{0}, \\sigma^2 \\mathbf{M_{xx}}^{-1} \\right) \n",
    "$$\n",
    "\n",
    "where we will estimate $\\hat{\\mathbf{M}}_{\\mathbf{xx}} = \\frac{1}{n} \\mathbf{X}^\\top\\mathbf{X}$ and $\\sigma^2$ using the sample variance. \n",
    "\n",
    "$$\n",
    "S^2 = \\frac{1}{n - k} \\hat{\\mathbf{e}}^\\top \\hat{\\mathbf{e}}\n",
    "$$\n",
    "\n",
    "This leads to the variance estimator of the OLS estimator\n",
    "\n",
    "$$\n",
    "\\hat{\\text{Var}}[\\hat{\\boldsymbol{\\beta}}_{OLS}] = S^2 \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "If the error term is heteroskedastic then $\\sigma_i^2$ differs between observations. [Heteroscedastic robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors) can be obtained using (under some regularity conditions)\n",
    "\n",
    "$$\n",
    "\\hat{\\text{Var}}[\\hat{\\boldsymbol{\\beta}}_{OLS}] = \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1} \\mathbf{X}^\\top \\hat{\\boldsymbol{\\Omega}}\\mathbf{X} \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\boldsymbol{\\Omega}} = \\text{Diag}[\\hat{e}_i^2]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-generic",
   "metadata": {},
   "source": [
    "## A general framework: m-estimators \n",
    "\n",
    "In financial economics we cannot solely rely on linear regressions, we also need to be able to estimate parameters of different densities or highly non-linear models. \n",
    "\n",
    "Some of the principles observed for OLS can be extended to more general type of estimators namely [m-estimators](https://en.wikipedia.org/wiki/M-estimator) that includes _Non-linear Least Squares (NLS)_ and _Maximum Likelihood Estimation (MLE)_. \n",
    "\n",
    "### Definition of m-estimator\n",
    "\n",
    "An m-estimator $\\hat{\\theta}$ of the $k \\times 1$ parameter vector $\\theta$ minimizes the objective function $Q_n(\\theta)$ that can be written as a sample average\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = \\frac{1}{n} \\sum_{i=1}^n q(y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "where $q(\\cdot)$ is scalar function. We assume independence over $i$.  \n",
    "\n",
    "Clearly, with $q(y_i, \\mathbf{x}_i; \\beta) = (y_i - \\mathbf{x}_i^\\top \\beta)^2$ OLS is an m-estimator!  The m-estimator is computed as the solution to the FOC \n",
    "\n",
    "$$\n",
    "\\left. \\frac{\\partial Q_n(\\theta)}{\\partial \\theta} \\right \\vert _{\\theta = \\hat{\\theta}} = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta} \\right \\vert _{\\theta = \\hat{\\theta}} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "The $k$ equations with $k$ unknowns will sometimes have an explicit analytical solution, but often we need to use numerical methods to find a solution. \n",
    "\n",
    "### Some comments on properties of m-estimators\n",
    "\n",
    "Generally, it can be an audacious task to derive the properties of m-estimators such as NLS and MLE and it is not the objective of the course. \n",
    "\n",
    "__Consistency__\n",
    "\n",
    "We have to assume that there is a particular data generating process and a corresponding value of $\\theta$, say $\\theta_0$, which generate the data. We need to have that $\\theta_0$ is unique in the sense that other values of $\\theta$ would not correspond to the same data-generating proces ([identification](https://en.wikipedia.org/wiki/Identifiability)). \n",
    "\n",
    "In a linear regression model this holds when $\\mathbf{X}$ has full rank since then \n",
    "\n",
    "$$\n",
    "\\mathbf{x}^\\top \\beta_1 = \\mathbf{x}^\\top \\beta_2\n",
    "$$\n",
    "\n",
    "if and only if $\\beta_1=\\beta_2$. \n",
    "\n",
    "__Limit distribution__\n",
    "\n",
    "As in the case for OLS, the m-estimators that we consider will typically converge asymptotically to a multivariate normal\n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta} - \\theta_0) \\to^d N(0, \\mathbf{A}_0^{-1} \\mathbf{B} \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\mathbf{A}_0 = \\text{plim} \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\theta_0} = \\text{lim} \\frac{1}{n} \\sum_{i=1}^n \\text{E} \\left[\\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\theta_0} \\right]\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\mathbf{B}_0 = \\text{plim} \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\theta_0} = \\text{lim} \\frac{1}{n} \\sum_{i=1}^n \\text{E} \\left[\\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\theta_0} \\right]\n",
    "$$\n",
    "\n",
    "We note that for OLS, we would have \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{A}_0 & =  \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{X} \\right]  =  \\mathbf{M_{xx}} \\\\\n",
    "\\mathbf{B}_0 & = \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top \\mathbf{e} \\mathbf{e}^\\top\\mathbf{X}   \\right]  = \\mathbf{M_{x\\Omega x}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that we obtain the asymptotic distribution presented above. \n",
    "\n",
    "We also note that we could use the below estimators when approximating the limit distribution \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mathbf{A}} & = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\hat{\\theta}}  \\\\\n",
    "\\hat{\\mathbf{B}} & = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\hat{\\theta}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-evaluation",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation (MLE)\n",
    "\n",
    "[Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) is one of the most widely used estimation methods with a number of diserable properties, e.g. it will be the most efficient estimator among consistent asymptotically normal estimators. \n",
    "\n",
    "The MLE of $\\theta_0$ basically seeks to select the $\\theta$ that maximizes the likelihood of observing the actual sample. The joint density of the random sample $f(\\mathbf{y}, \\mathbf{X}; \\theta)$, which will define as the likelihood function, can under an independence assumption be written as the product of the marginal densities \n",
    "\n",
    "$$\n",
    "L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = f(\\mathbf{y}, \\mathbf{X}; \\theta) = \\prod_{i=1}^n f_{y, \\mathbf{x}_i} (y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "Since $\\ln$ is a positive monotone transformation, we can equivalently maximize the log-likelihood function \n",
    "\n",
    "$$\n",
    "\\mathcal{L}_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = \\ln L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = \\sum_{i=1}^n \\ln f_{y, \\mathbf{x}_i} (y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "### Conditional likelihood\n",
    "\n",
    "We can factorize a density as the product between the conditional and marginal density\n",
    "\n",
    "$$\n",
    "L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = f(\\mathbf{y}, \\mathbf{X}; \\theta) = f(\\mathbf{y} \\vert \\mathbf{X}; \\theta) f(\\mathbf{X}; \\theta)  \n",
    "$$\n",
    "\n",
    "Typically, we will only focus on the conditional density $f(\\mathbf{y} \\vert \\mathbf{X}; \\theta)$ since we are interested in $\\mathbf{y}$ given $\\mathbf{X}$ (we will do this below). It will not be an issue if $\\mathbf{y}$ and $\\mathbf{X}$ depends on different sets of parameters, which often will be a reasonable assumption (but not always). \n",
    "\n",
    "In _time series modelling_, we also often use the notion of a conditional likelihood function since we cannot always apply an independence assumption.  Assume e.g. that $y_t$ depends on $y_{t-1}$ (and no regressors) then we could factorize (using T to indicate time series context)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_T (\\theta \\vert \\mathbf{y}) &= f_{y_0, \\dots, y_T}(y_0, \\dots, y_T; \\theta) \\\\\n",
    "&= f_y(y_0; \\theta) f_{y_1, \\dots, y_T}(y_1, \\dots, y_T; \\theta) \\\\\n",
    "&= f_y(y_0; \\theta) \\prod_{t=1}^T f_{y_t \\vert y_{t-1}}(y_t \\vert y_{t-1}; \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "dropping $f_y(y_0; \\theta)$ will result in the conditional likelihood function that is conditional on the starting value. \n",
    "\n",
    "### M-estimator\n",
    "\n",
    "In order to be able to use the results for m-estimators, we just divide the log-likelihood function with $n$\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = \\frac{1}{n} \\mathcal{L}_n (\\theta) = \\frac{1}{n} \\sum_{i=1}^n \\ln f_{y, \\mathbf{x}_i} (y_i \\vert \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "__Remember:__ Most optimizers seek to minimize a function so we may need to multiply with minus one and then minimize. \n",
    "\n",
    "__Example: Bernoulli__\n",
    "\n",
    "Assume that we observe a realization of the random sample $Y_1, ...., Y_{n}$ where $Y_i\\sim \\text{Bernoulli}(p), i=1,...,n$  \n",
    "\n",
    "We can write the likelihood function as \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "L(p) = \\prod_{i=1}^n f_Y(y_i;p) = \\prod_{i=1}^n p^{y_i}(1-p) ^{1-y_i} = p^{\\sum_{i=1}^n y_i}(1-p)^{\\sum_{i=1}^n (1-y_i)}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "We want to maximize with respect to $p$, but we first take the logarithm \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\ln L(p) = \\ln (p) \\sum_{i=1}^n y_i + \\ln(1-p) \\sum_{i=1}^n (1-y_i)\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The first order condition is (take derivative wrt. $p$)\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\frac{1}{p} \\sum_{i=1}^n y_i - \\frac{1}{1-p} \\left[n - \\sum_{i=1}^n y_i \\right] = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "such that we obtain the maximum-likelihood estimate\n",
    "\n",
    "$$\n",
    "p_e = \\frac{1}{n}\\sum_{i=1}^n y_i\n",
    "$$\n",
    "\n",
    "Below, we see a simple implementation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "local-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4499999960279612"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define log-likelihood function\n",
    "\"\"\"\n",
    "\n",
    "def log_likelihood_function(p, x):\n",
    "    \n",
    "    log_like = np.log(p) * np.sum(x) + np.log(1-p) * np.sum(1-x)\n",
    "    \n",
    "    return log_like\n",
    "\n",
    "\"\"\"\n",
    "Generate data\n",
    "\"\"\"\n",
    "np.random.seed(5)\n",
    "bernoulli_data = np.random.binomial(1,0.5,size=20)\n",
    "\n",
    "\"\"\"\n",
    "Minimize negative of log-likelihood\n",
    "\"\"\"\n",
    "neg_log_lik = lambda p: -log_likelihood_function(p, bernoulli_data)\n",
    "\n",
    "res = minimize(neg_log_lik, 0.5, bounds={(0.00001,0.99999)})\n",
    "res.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-person",
   "metadata": {},
   "source": [
    "### Information matrix equality\n",
    " \n",
    "The [information matrix](https://en.wikipedia.org/wiki/Fisher_information) can equivalently be written as \n",
    "\n",
    "$$\n",
    "I(\\theta) = -\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] = \\text{E} \\left[ \\left. \\frac{\\partial \\mathcal{L}_n (\\theta)}{\\partial \\theta } \\frac{\\partial \\mathcal{L}_n (\\theta)}{\\partial \\theta^\\top } \\right \\vert_{\\theta = \\theta_0}\\right]\n",
    "$$\n",
    "\n",
    "### Asymptotic distribution \n",
    "\n",
    "The Information matrix equality implies that $-\\mathbf{A}_0 = \\mathbf{B}_0$ such that $\\mathbf{A}_0 ^{-1}\\mathbf{B}_0 \\mathbf{A}_0 ^{-1} =  \\mathbf{B}_0 ^{-1}=  -\\mathbf{A}_0^{-1}$. \n",
    "\n",
    "Using the results for m-estimators, we have \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{MLE} - \\theta_0) \\to^d N(0, -\\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "or alternatively written as \n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{MLE} \\sim ^a N\\left(\\theta_0, -\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}\\right)\n",
    "$$\n",
    "\n",
    "Note that \n",
    "\n",
    "$$\n",
    "V(\\theta) = -\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}\n",
    "$$\n",
    "\n",
    "corresponds to Cramér-Rao's lower bound such that the MLE is the most efficient estimator among consistent and asympotically normal estimators. \n",
    "\n",
    "__Note:__ To avoid confusion we may note that \n",
    "\n",
    "$$\n",
    "-\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1} = -\\left(\\text{E} \\left[ \\left. \\sum_{i=1}^n \\frac{\\partial^2 \\ln f_y(y_i; \\theta) }{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1} = - \\left(n\\text{E} \\left[ \\left.  \\frac{\\partial^2 \\ln f_y(y_i; \\theta) }{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-porcelain",
   "metadata": {},
   "source": [
    "## Non-linear Least Squares (NLS)\n",
    "\n",
    "A non-linear regression model specifies the conditional mean as \n",
    "\n",
    "$$\n",
    "\\text{E}[y_i \\vert \\mathbf{x}_i] = g(\\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "or equivalently written as (assuming that $\\text{E}[\\mathbf{e} \\vert \\mathbf{x}] = 0$)\n",
    "\n",
    "$$\n",
    "y_i = g(\\mathbf{x}_i; \\theta) + e_i\n",
    "$$\n",
    "\n",
    "Clearly, linear regression is the special case $g(\\mathbf{x}_i; \\beta) = \\mathbf{x}_i^\\top \\beta$. \n",
    "\n",
    "The NLS estimator will minimize the sum of squared residuals or minimize (we can scale with $1/2$ without loss of generality)\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = - \\frac{1}{2n} \\sum_{i=1}^n (y_i - g(\\mathbf{x}_i; \\theta))^2\n",
    "$$\n",
    "\n",
    "The FOC gives us \n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q_n(\\theta)}{\\partial \\theta} = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g(\\mathbf{x}_i; \\theta)}{\\partial \\theta} (y_i - g(\\mathbf{x}_i; \\theta)) = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "or more compactly using matrix notation \n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q_n(\\theta)}{\\partial \\theta} = \\frac{1}{n}\\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} (\\mathbf{y}- \\mathbf{g})\n",
    "$$\n",
    "\n",
    "For consistency of the NLS estimator, it is crucial that the mean is specified correctly. \n",
    "\n",
    "Assuming a covariance matrix for the errors $\\text{E}[\\mathbf{e} \\mathbf{e}^\\top \\vert \\mathbf{X}] = \\boldsymbol{\\Omega}_0$\n",
    "and under regularity conditions, it will be the case that \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{NLS} - \\theta_0) \\to^d N(0, \\mathbf{A}_0^{-1} \\mathbf{B}_0 \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{A}_0 &= \\text{plim} \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}  \\right \\vert_{\\theta = \\theta_0}\\\\\n",
    "\\mathbf{B}_0 &= \\text{plim} \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\boldsymbol{\\Omega}_0 \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "A reasonable estimator for $\\mathbf{A}_0$ is \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{A}} = \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}\\right \\vert_{\\theta = \\hat{\\theta}_{NLS}}\n",
    "$$\n",
    "\n",
    "For $\\mathbf{B}_0$ it depends (just as in the OLS case) on the assumption we can make about $\\boldsymbol{\\Omega}_0$. Assuming independence implies that $\\boldsymbol{\\Omega}_0$ must be a diagonal matrix. If homoskedasticity of the error term can be assumed then \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{NLS} - \\theta_0) \\to^d N(0, \\sigma^2 \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "and we just need to estimate $\\sigma^2$ using the sample variance. If we allow for heteroskedasticity, we can estimate \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{B}} = \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\hat{\\boldsymbol{\\Omega}}\\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}\\right \\vert_{\\theta = \\hat{\\theta}_{NLS}}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\boldsymbol{\\Omega}} = \\text{Diag}[\\hat{e}_i^2]$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-vulnerability",
   "metadata": {},
   "source": [
    "## Application: Exponential distribution \n",
    "\n",
    "The [exponential density](https://en.wikipedia.org/wiki/Exponential_distribution) is given by\n",
    "\n",
    "$$\n",
    "f_Y(y) = \\lambda e^{-\\lambda y}, \\; y > 0, \\; \\lambda > 0\n",
    "$$\n",
    "\n",
    "The mean and variance is respectively $1/\\lambda$ and $1/\\lambda^2$. The exponential distribution can be used to describe the time for a continuous process to change state or for an event to occur, e.g. time between roadkills on a given road. \n",
    "\n",
    "Below we plot the density of a exponential density (with the above parameterization) assuming $\\lambda = 12$. On average, we will wait $1/12$ time periods for one event to occur (one month if $y$ is measured in years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suffering-affair",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lam = 12.0\n",
    "y_values = np.linspace(0.001, 2.0, 1000)\n",
    "pdf_values = stats.expon.pdf(y_values, scale = 1 / lam)\n",
    "\n",
    "\"\"\"\n",
    "Plotting\n",
    "\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(y_values, pdf_values, color=\"blue\")\n",
    "ax.set_xlabel('$y$');\n",
    "ax.set_ylabel('$f_Y(y)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-transaction",
   "metadata": {},
   "source": [
    "We may introduce explanatory variables by specifying \n",
    "\n",
    "$$\n",
    "\\lambda = e^{\\mathbf{x}^\\top \\beta} \n",
    "$$\n",
    "\n",
    "ensuring $\\lambda > 0$ and specifying the conditional mean as \n",
    "\n",
    "$$\n",
    "\\text{E}[y \\vert \\mathbf{x}] = e^{-\\mathbf{x}^\\top \\beta}\n",
    "$$\n",
    "\n",
    "Assume that we observe a realization of a iid random sample $y_i, \\mathbf{x}_i$, $i = 1, ... n$. \n",
    "\n",
    "### The MLE \n",
    "\n",
    "The (conditional) log-likehood function can be written\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_n (\\beta) =  \\sum_{i=1}^n  \\left[ \\mathbf{x}_i^\\top \\beta - e^{\\mathbf{x}_i^\\top \\beta} y_i\\right]\n",
    "$$\n",
    "\n",
    "with the FOC \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}_n (\\beta)}{\\partial \\beta} =  \\sum_{i=1}^n  \\left[ \\mathbf{x}_i  - \\mathbf{x}_i e^{\\mathbf{x}_i^\\top \\beta} y_i\\right] = \\sum_{i=1}^n  \\mathbf{x}_i\\left[ 1  - e^{\\mathbf{x}_i^\\top \\beta} y_i\\right] = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "To obtain the variance of the MLE estimator, it will be useful to note that (using the more general notation of m-estimators)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n  \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta \\partial \\beta^\\top} &=  \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i\\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=      \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### The NLS estimator\n",
    "\n",
    "A non-linear least squares estimator can be implemented by estimating \n",
    "\n",
    "$$\n",
    "y_i = e^{\\mathbf{x}_i^\\top \\beta} + e_i\n",
    "$$\n",
    "\n",
    "We also note that the error term is heteroskedastic since $\\text{Var}[y_i] = 1 / [e^{\\mathbf{x}_i^\\top \\beta}]^2$. Our FOC reads\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n (y_i - e^{\\mathbf{x}_i^\\top \\beta})e^{\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "For calculating variance, we note that (using the notation for NLS above)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &= \\frac{1}{n} \\sum_{i=1}^n e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\sigma_i^2 \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=  \\frac{1}{n} \\sum_{i=1}^n e^{-2\\mathbf{x}_i^\\top \\beta} e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-interview",
   "metadata": {},
   "source": [
    "### Simulating data and implementing estimators\n",
    "\n",
    "We consider 10,000 iid draws from the data generating process\n",
    "\n",
    "$$\n",
    "y \\sim \\text{Exp}(\\beta_1 + \\beta_2 x)\n",
    "$$\n",
    "\n",
    "with $x \\sim N(1, 1)$ and $(\\beta_1, \\beta_2) = (1, -2)$. \n",
    "\n",
    "Below we implement the (negative) log-likelhood function and minimize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promotional-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate data\n",
    "\"\"\"\n",
    "n_sim = 10000\n",
    "\n",
    "beta1 = 2.0\n",
    "beta2 = -1.0\n",
    "beta = np.array([beta1, beta2])\n",
    "\n",
    "x_data = np.random.normal(loc=1, scale=1, size=n_sim)\n",
    "x_data = np.c_[np.ones(n_sim), x_data]\n",
    "y_data = np.random.exponential(scale = 1 / np.exp(x_data @ beta), size=n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sunset-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.97401107, -0.99806723])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define log-likelihood function (negative)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def log_likelihood_function(beta, y, x, individual=False):\n",
    "    \n",
    "    log_like = x @ beta - np.exp(x @ beta) * y\n",
    "    \n",
    "    if individual: \n",
    "        return -log_like\n",
    "    else:\n",
    "        return -np.sum(log_like)\n",
    "\n",
    "\"\"\"\n",
    "Minimize negative log-likelihood \n",
    "\"\"\"\n",
    "res_dict = {}\n",
    "res_dict['MLE'] = {}\n",
    "\n",
    "res = minimize(log_likelihood_function, [0.5, 0.5], args=(y_data, x_data))\n",
    "res_dict['MLE']['beta1'] = res.x[0]\n",
    "res_dict['MLE']['beta2'] = res.x[1]\n",
    "params_mle = res.x\n",
    "params_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-savage",
   "metadata": {},
   "source": [
    "We have several different options when calculating the variance of the estimator. In this particular model, we know that \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{E}\\left[\\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2 \\right] &= \\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2 \\right] \\\\\n",
    "        & = \\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\\\\\n",
    "\\text{E}\\left[ \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i \\right] &= -\\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Given our assumptions about $x$, we know that \n",
    "\n",
    "$$\n",
    "\\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right] = \\text{E}\\left[\\begin{bmatrix} 1 \\\\ x_i \\end{bmatrix} \\begin{bmatrix} 1 & x_i \\end{bmatrix} \\right] = \\text{E}\\left[\\begin{bmatrix} 1 & x_i \\\\ x_i & x_i^2 \\end{bmatrix} \\right] = \\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "such that the variance is given by\n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\beta}] = - \\left[-n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\\right]^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "relevant-coalition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0002, -0.0001],\n",
       "       [-0.0001,  0.0001]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_xx_true = np.array([[1, 1], [1, 2]])\n",
    "param_mle_cov_true = np.linalg.inv(n_sim*exp_xx_true)\n",
    "\n",
    "res_dict['MLE']['std1_true'] = np.sqrt(param_mle_cov_true[0,0])\n",
    "res_dict['MLE']['std2_true'] = np.sqrt(param_mle_cov_true[1,1])\n",
    "\n",
    "# print covariance matrix of parameter estimator \n",
    "param_mle_cov_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-yorkshire",
   "metadata": {},
   "source": [
    "Generally, we observe real data, i.e. we do not know the true data generating process, such that we need to estimate the variance of the estimator. We need to evaluate the below expression at the MLE estimate. \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n  \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta \\partial \\beta^\\top} &= \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=     \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "correct-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wooden-clearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ji,jk->jik',x_data, x_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "civic-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient \n",
    "\"\"\"\n",
    "\n",
    "def outer_gradient(beta, x, y): \n",
    "    \n",
    "    return np.sum(((1 - np.exp(x @ beta) * y)**2)[:, None, None] * np.einsum('ji,jk->jik',x, x), axis=0)\n",
    "\n",
    "def outer_gradient_alternative(beta, x, y): \n",
    "    \n",
    "    x_new = (1 - np.exp(x @ beta) * y)[:, None] * x\n",
    "    \n",
    "    return x_new.T @ x_new\n",
    "\n",
    "\"\"\"\n",
    "Hessian \n",
    "\"\"\"\n",
    "\n",
    "def hessian(beta, x, y): \n",
    "    \n",
    "    return -np.sum((np.exp(x_data @ beta) * y)[:, None, None] * \n",
    "                   np.einsum('ji,jk->jik',x, x), axis=0) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "institutional-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10117.42388741, 10574.56857364],\n",
       "       [10574.56857364, 21671.14671278]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_gradient(params_mle, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "metallic-drunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10117.42388741, 10574.56857364],\n",
       "       [10574.56857364, 21671.14671278]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_gradient_alternative(params_mle, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "executed-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = hessian(params_mle, x_data, y_data)\n",
    "B = outer_gradient(params_mle, x_data, y_data)\n",
    "\n",
    "param_mle_cov_A = np.linalg.inv(-A)\n",
    "res_dict['MLE']['std1_A'] = np.sqrt(param_mle_cov_A[0,0])\n",
    "res_dict['MLE']['std2_A'] = np.sqrt(param_mle_cov_A[1,1])\n",
    "\n",
    "param_mle_cov_B = np.linalg.inv(B)\n",
    "res_dict['MLE']['std1_B'] = np.sqrt(param_mle_cov_B[0,0])\n",
    "res_dict['MLE']['std2_B'] = np.sqrt(param_mle_cov_B[1,1])\n",
    "\n",
    "param_mle_cov_sandwich = np.linalg.inv(A) @ B @ np.linalg.inv(A)\n",
    "res_dict['MLE']['std1_SW'] = np.sqrt(param_mle_cov_sandwich[0,0])\n",
    "res_dict['MLE']['std2_SW'] = np.sqrt(param_mle_cov_sandwich[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floppy-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.97106342e-04, -9.72262107e-05],\n",
       "       [-9.72262107e-05,  9.73462283e-05]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A\n",
    "param_mle_cov_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nasty-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.91148815e-04, -9.31778017e-05],\n",
       "       [-9.31778017e-05,  8.95159024e-05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on B\n",
    "param_mle_cov_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concerned-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00020328, -0.00010155],\n",
       "       [-0.00010155,  0.00010604]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A^{-1}BA^{-1} \"Sandwich formula\"\n",
    "param_mle_cov_sandwich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-alabama",
   "metadata": {},
   "source": [
    "The above calculations assume that we have derived the formula for \"A\" and \"B\" such that we \"just\" need to evaluate at the MLE estimate. \n",
    "\n",
    "However, it may be a tedious task. A common approach is to use numerical derivatives or other tools to calculate \"A\" and \"B\". Below we use the `statsmodels.tools.numdiff` package.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "champion-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = approx_fprime(params_mle, log_likelihood_function, args=(y_data, x_data, True))\n",
    "B_approx = scores.T @ scores  #np.sum(np.einsum('ji,jk->jik', scores, scores), axis=0)\n",
    "\n",
    "A_approx = -approx_hess(params_mle, log_likelihood_function, args=(y_data, x_data))\n",
    "\n",
    "param_mle_cov_A_num = np.linalg.inv(-A_approx)\n",
    "res_dict['MLE']['std1_A_num'] = np.sqrt(param_mle_cov_A_num[0,0])\n",
    "res_dict['MLE']['std2_A_num'] = np.sqrt(param_mle_cov_A_num[1,1])\n",
    "\n",
    "param_mle_cov_B_num = np.linalg.inv(B_approx)\n",
    "res_dict['MLE']['std1_B_num'] = np.sqrt(param_mle_cov_B_num[0,0])\n",
    "res_dict['MLE']['std2_B_num'] = np.sqrt(param_mle_cov_B_num[1,1])\n",
    "\n",
    "param_mle_cov_sandwich_num = np.linalg.inv(A_approx) @ B_approx @ np.linalg.inv(A_approx)\n",
    "res_dict['MLE']['std1_SW_num'] = np.sqrt(param_mle_cov_sandwich_num[0,0])\n",
    "res_dict['MLE']['std2_SW_num'] = np.sqrt(param_mle_cov_sandwich_num[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worst-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.97106337e-04, -9.72262079e-05],\n",
       "       [-9.72262079e-05,  9.73462256e-05]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A\n",
    "param_mle_cov_A_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sexual-breakdown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01714629e-04, -9.84278872e-05],\n",
       "       [-9.84278872e-05,  9.41727929e-05]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on B\n",
    "param_mle_cov_B_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "temporal-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.92627079e-04, -9.61372876e-05],\n",
       "       [-9.61372876e-05,  1.00833162e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A^{-1}BA^{-1} \"Sandwich formula\"\n",
    "param_mle_cov_sandwich_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaging-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLE': {'beta1': 1.974011073890516,\n",
       "  'beta2': -0.9980672281314584,\n",
       "  'std1_true': 0.01414213562373095,\n",
       "  'std2_true': 0.01,\n",
       "  'std1_A': 0.014039456603625048,\n",
       "  'std2_A': 0.009866419224603337,\n",
       "  'std1_B': 0.013825657850551797,\n",
       "  'std2_B': 0.00946128439440952,\n",
       "  'std1_SW': 0.0142576030187802,\n",
       "  'std2_SW': 0.010297583571449402,\n",
       "  'std1_A_num': 0.014039456437573214,\n",
       "  'std2_A_num': 0.009866419084660134,\n",
       "  'std1_B_num': 0.014202627548821187,\n",
       "  'std2_B_num': 0.009704266736059564,\n",
       "  'std1_SW_num': 0.013879015763792479,\n",
       "  'std2_SW_num': 0.010041571706641968}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-frame",
   "metadata": {},
   "source": [
    "We have specified the model correctly and have lots of data, so it is no surprice that maximum likelihood performs well. Due to the information matrix equality, then using different variance estimators gives us very similar results. \n",
    "\n",
    "Next, we define the NLS objective and minimze it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suitable-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_nls(beta, y, x, individual=False): \n",
    "    \n",
    "    loss = np.square(y - np.exp(-x @ beta))\n",
    "    \n",
    "    if individual: \n",
    "        return loss\n",
    "    else:\n",
    "        return np.sum(loss) / len(y)\n",
    "    \n",
    "def foc_nls(beta, y, x): \n",
    "    \n",
    "    der = (y - np.exp(-x @ beta)) * np.exp(-x @ beta) @ x\n",
    "    \n",
    "\n",
    "    return np.sum(der)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "powerful-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.80722036, -0.92821435])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict['NLS'] = {}\n",
    "\n",
    "res = minimize(objective_nls, [1.0, -2.0], args=(y_data, x_data, False))\n",
    "res_dict['NLS']['beta1'] = res.x[0]\n",
    "res_dict['NLS']['beta2'] = res.x[1]\n",
    "params_nls = res.x\n",
    "params_nls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "present-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 0.9972960069476642\n",
       " hess_inv: array([[ 5.00606744, -1.63539313],\n",
       "       [-1.63539313,  0.59969104]])\n",
       "      jac: array([-2.98023224e-08, -7.45058060e-08])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 84\n",
       "      nit: 26\n",
       "     njev: 28\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 1.80722036, -0.92821435])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "trained-military",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_data[:, 1], y_data)\n",
    "plt.scatter(x_data[:, 1],  np.exp(-x_data @ params_nls));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-extra",
   "metadata": {},
   "source": [
    "Next step is to calculate the variance of the NLS estimator. Again, we can either use the exact analytical expressions or use numerical derivatives. We consider the analytical derivatives. \n",
    "\n",
    "We implement \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &= \\frac{1}{n} \\sum_{i=1}^n e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\sigma_i^2 \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=  \\frac{1}{n} \\sum_{i=1}^n e^{-2\\mathbf{x}_i^\\top \\beta} e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "certain-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_g(beta, y, x):\n",
    "    return np.exp(-x @ beta)[:, None] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "married-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_g = calculate_scores_g(params_nls, y_data, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tight-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = scores_g.T @ scores_g\n",
    "B = scores_g.T @ np.diag(np.exp(-2*x_data @ params_nls)) @ scores_g\n",
    "B_alt = scores_g.T @ np.diag((y_data - np.exp(-x_data @ params_nls) )**2) @ scores_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "weird-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_nls_cov_A_num = np.linalg.inv(A) #<-- understates variance\n",
    "res_dict['NLS']['std1_A_num'] = np.sqrt(param_nls_cov_A_num[0,0])\n",
    "res_dict['NLS']['std2_A_num'] = np.sqrt(param_nls_cov_A_num[1,1])\n",
    "\n",
    "param_nls_cov_B_num = np.linalg.inv(B) #<-- understates variance\n",
    "res_dict['NLS']['std1_B_num'] = np.sqrt(param_nls_cov_B_num[0,0])\n",
    "res_dict['NLS']['std2_B_num'] = np.sqrt(param_nls_cov_B_num[1,1])\n",
    "\n",
    "param_nls_cov_sandwich_num = np.linalg.inv(A) @ B @ np.linalg.inv(A) #<-- valid estimator due to heteroskedasticity\n",
    "res_dict['NLS']['std1_SW_num'] = np.sqrt(param_nls_cov_sandwich_num[0,0])\n",
    "res_dict['NLS']['std2_SW_num'] = np.sqrt(param_nls_cov_sandwich_num[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "frank-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00109893, -0.00036138],\n",
       "       [-0.00036138,  0.00013217]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_A_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "chronic-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.89741818e-04, -7.18559911e-05],\n",
       "       [-7.18559911e-05,  1.82914807e-05]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_B_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appreciated-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02092169, -0.00939263],\n",
       "       [-0.00939263,  0.00429182]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_sandwich_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "powerful-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLE': {'beta1': 1.974011073890516,\n",
       "  'beta2': -0.9980672281314584,\n",
       "  'std1_true': 0.01414213562373095,\n",
       "  'std2_true': 0.01,\n",
       "  'std1_A': 0.014039456603625048,\n",
       "  'std2_A': 0.009866419224603337,\n",
       "  'std1_B': 0.013825657850551797,\n",
       "  'std2_B': 0.00946128439440952,\n",
       "  'std1_SW': 0.0142576030187802,\n",
       "  'std2_SW': 0.010297583571449402,\n",
       "  'std1_A_num': 0.014039456437573214,\n",
       "  'std2_A_num': 0.009866419084660134,\n",
       "  'std1_B_num': 0.014202627548821187,\n",
       "  'std2_B_num': 0.009704266736059564,\n",
       "  'std1_SW_num': 0.013879015763792479,\n",
       "  'std2_SW_num': 0.010041571706641968},\n",
       " 'NLS': {'beta1': 1.8072203587916136,\n",
       "  'beta2': -0.9282143471651557,\n",
       "  'std1_A_num': 0.03315010545389259,\n",
       "  'std2_A_num': 0.011496339697411114,\n",
       "  'std1_B_num': 0.017021804189629706,\n",
       "  'std2_B_num': 0.00427685406441439,\n",
       "  'std1_SW_num': 0.14464332683892678,\n",
       "  'std2_SW_num': 0.06551195385659007}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-nitrogen",
   "metadata": {},
   "source": [
    "## Estimation using SciPy\n",
    "\n",
    "`scipy` provides MLE methods for implemented distributions (see e.g. [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html)). For instance, we can fit the parameters of a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "center-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE mu: 5.01203350388008\n",
      "MLE std: 1.0044464679061866\n",
      "\n",
      "SciPy mu: 5.01203350388008\n",
      "SciPy std: 1.0044464679061866\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simulate Normal data and estimate parameters\n",
    "\"\"\"\n",
    "\n",
    "num_sim = 10000\n",
    "sigma = 1\n",
    "mu = 5\n",
    "\n",
    "\n",
    "norm_data = np.random.normal(loc=mu, scale=sigma, size=num_sim)\n",
    "\n",
    "# Known MLE \n",
    "mu_est = np.mean(norm_data)\n",
    "variance_est = np.var(norm_data)\n",
    "sigma_est = np.sqrt(variance_est)\n",
    "\n",
    "print(\"MLE mu: \" + str(mu_est))\n",
    "print(\"MLE std: \" + str(sigma_est) + \"\\n\")\n",
    "\n",
    "# fit using SciPy\n",
    "mu_scipy_est, sigma_scipy_est = stats.norm.fit(norm_data)\n",
    "\n",
    "print(\"SciPy mu: \" + str(mu_scipy_est))\n",
    "print(\"SciPy std: \" + str(sigma_scipy_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-bosnia",
   "metadata": {},
   "source": [
    "## Estimation using Statsmodels\n",
    "\n",
    "`scipy` provides a quick MLE implementation for different distributions, but may not be applicable for more complicated problem. \n",
    "\n",
    "`statsmodels` provides a framework for implementing generic MLE estimators (see [docs](https://www.statsmodels.org/dev/examples/notebooks/generated/generic_mle.html)). Let us try to implement our exponential model using `statsmodels`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "healthy-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022826\n",
      "         Iterations: 50\n",
      "         Function evaluations: 98\n",
      "                             Exponential Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -228.26\n",
      "Model:                    Exponential   AIC:                             460.5\n",
      "Method:            Maximum Likelihood   BIC:                             474.9\n",
      "Date:                Wed, 01 Sep 2021                                         \n",
      "Time:                        22:01:58                                         \n",
      "No. Observations:               10000                                         \n",
      "Df Residuals:                    9998                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.9740      0.014    140.597      0.000       1.946       2.001\n",
      "x1            -0.9980      0.010   -101.154      0.000      -1.017      -0.979\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "# overwrite loglikelihood function in Generic Likelihood Class\n",
    "class Exponential(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglike(self, params):\n",
    "        exog = self.exog\n",
    "        endog = self.endog\n",
    "        return (exog @ params - np.exp(exog @ params) * endog).sum()\n",
    "\n",
    "# fit models\n",
    "exponential_fit = Exponential(y_data, x_data).fit()\n",
    "\n",
    "# print results\n",
    "print(exponential_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "respiratory-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.97401107, -0.99806723])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Our previous estimates\n",
    "\"\"\"\n",
    "\n",
    "params_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-passion",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## Books\n",
    "\n",
    " [Microeconometrics: Methods and Applications, Cameron and Trivedi (2005)](https://www.cambridge.org/highereducation/books/microeconometrics/982158DE989697607C858068ED05C7B1#overview)\n",
    " \n",
    " [Econometric Analysis 7th edition, William H. Greene (2012)](https://www.amazon.com/Econometric-Analysis-7th-William-Greene/dp/0131395386)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_fin_econ",
   "language": "python",
   "name": "python_for_fin_econ"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
